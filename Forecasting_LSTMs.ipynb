{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forecasting_LSTMs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoE0sgecPTFJX2uF1xkADe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratikhyaManas/EnergyForecasting/blob/main/Forecasting_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PsuexkXDrBF",
        "outputId": "863882db-88b3-401f-9a5e-c38fc544d8e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEVUXPp3FpaG"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR9WCP83F-VE",
        "outputId": "2a42f4e6-349a-4110-b005-7307fab2609d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhMJYLkiGT-J"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Dataset/\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gp3JUUTG71z"
      },
      "source": [
        "extension = 'csv'\n",
        "all_files = [i for i in glob.glob('*.{}'.format(extension))]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0wfwq2SHBA2"
      },
      "source": [
        "#combine all files in the list\n",
        "df = pd.concat([pd.read_csv(f, low_memory=False) for f in all_files])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2rCzeaWJYkP"
      },
      "source": [
        "#export to csv\n",
        "df.to_csv(\"appended.csv\", index=False, encoding='utf-8-sig')\n",
        "\n",
        "df['Date Time'] = pd.to_datetime(df['SETTLEMENTDATE'])\n",
        "df['Day'] = df['Date Time'].dt.day\n",
        "df['Month'] = df['Date Time'].dt.month\n",
        "df['Year'] = df['Date Time'].dt.year\n",
        "df['Hour'] = df['Date Time'].dt.hour\n",
        "df['Minute'] = df['Date Time'].dt.minute"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVkZWaK-Jep3"
      },
      "source": [
        "df['Demand'] = pd.to_numeric(df['TOTALDEMAND'],errors='coerce')\n",
        "df.drop(['REGION'],axis=1,inplace=True)\n",
        "df.drop(['SETTLEMENTDATE'],axis=1,inplace=True)\n",
        "df.drop(['TOTALDEMAND'],axis=1,inplace=True)\n",
        "df.drop(['RRP'],axis=1,inplace=True)\n",
        "df.drop(['PERIODTYPE'],axis=1,inplace=True)\n",
        "df.drop(['Date Time'],axis=1,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GddNtQSjJjdQ"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "for i in range(0,df.shape[0]-48):\n",
        "    X.append(df.iloc[i:i+48, 5])\n",
        "    y.append(df.iloc[i+48, 5])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "y = np.reshape(y,(len(y), 1))\n",
        "\n",
        "X = np.delete(X,list(range(1,X.shape[1],2)),axis=1)\n",
        "X = np.delete(X,list(range(1,X.shape[0],2)),axis=0)\n",
        "y = np.delete(y,list(range(1,y.shape[0],2)),axis=0)\n",
        "\n",
        "pd.DataFrame(X).to_csv('appended_demand.csv')\n",
        "pd.DataFrame(y).to_csv('appended_demand_1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Trf6xgqJoVD"
      },
      "source": [
        "X = pd.read_csv('appended_demand.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22oP6hhuQ8C8"
      },
      "source": [
        "y = pd.read_csv('appended_demand_1.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imIjNoxgRDRL"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "\n",
        "X_train,X_test = X[:-480],X[-480:]\n",
        "y_train,y_test = y[:-480],y[-480:]\n",
        "\n",
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qderFsXROJb"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "# from tensorflow.python.keras.layers import LSTM, CuDNNLSTM\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(keras.Input(shape=(X_train.shape[1],1)))\n",
        "model.add(keras.layers.LSTM(50,return_sequences=True))\n",
        "model.add(keras.layers.LSTM(50,return_sequences=False))\n",
        "model.add(keras.layers.Dense(50,activation='relu'))\n",
        "model.add(keras.layers.Dense(1))\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "filepath = 'models/{epoch:02d}-{loss:.4f}-{val_loss:.4f}.hdf5'\n",
        "callbacks = [EarlyStopping(monitor='val_loss',patience=50),\n",
        "             ModelCheckpoint(filepath,monitor='loss',save_best_only=True,mode='min')]\n",
        "\n",
        "opt = optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,validation_split=0.2,epochs=20,callbacks=callbacks,batch_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqqm1Iv_glq3"
      },
      "source": [
        "model.load_weights('models/abc.hdf5')\n",
        "\n",
        "import time\n",
        "for i in range(0,X_test.shape[0]):\n",
        "    demand_summary = []\n",
        "    X_input = X_test[i, :, :]\n",
        "    X_input = np.reshape(X_input,(1,X_input.shape[0],1))\n",
        "    X_input = model.predict(X_input)\n",
        "    forecast = scaler.inverse_transform(X_input)\n",
        "\n",
        "    y_input = y_test[i,:]\n",
        "    y_input = np.reshape(y_input,(1,1))\n",
        "    actual = scaler.inverse_transform(y_input)\n",
        "\n",
        "    demand_summary.append(actual)\n",
        "    demand_summary.extend(forecast)\n",
        "\n",
        "    df_animate = pd.DataFrame(demand_summary)\n",
        "    df_animate = df_animate.T\n",
        "    df_animate.to_csv('real_time_demand.csv',mode='a',header=False,index=False)\n",
        "\n",
        "    print(demand_summary)\n",
        "    time.sleep(0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfp_khVxgvRK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import style\n",
        "\n",
        "style.use('fivethirtyeight')\n",
        "fig = plt.figure()\n",
        "fig.figsize = (8,4)\n",
        "ax1 = fig.add_subplot(1,1,1)\n",
        "\n",
        "def animate(i):\n",
        "    df = pd.read_csv('real_time_demand.csv')\n",
        "    ys_actual = df.iloc[:,0].values\n",
        "    ys_forecast = df.iloc[:,1].values\n",
        "\n",
        "    if len(ys_actual)>=120:\n",
        "        ys_actual = df.iloc[-120:,0].values\n",
        "        ys_forecast = df.iloc[-120:,1].values\n",
        "\n",
        "    xs = list(range(1,len(ys_actual)+1))\n",
        "    ax1.clear()\n",
        "    ax1.plot(xs,ys_actual)\n",
        "    ax1.plot(xs,ys_forecast)\n",
        "\n",
        "    ax1.set_title('One Hour Ahead of Load Forecasting - Victoria,Australia(MW)')\n",
        "    ax1.legend(['Actual','Forecast'],loc = 'lower_right')\n",
        "\n",
        "\n",
        "ani = animation.FuncAnimation(fig,animate,interval=500)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}